---
title: "Prediction_Model_MM"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(Gmisc)
library(tidyverse)
library(boot)
library(randomForest)
library(ranger)
library(neuralnet)
library(nnet)
library(e1071)
library(splines)
library(magrittr)
library(InformationValue)
library(tensorflow)
library(keras)
library(pROC)
```
*Loading base data, calculating spec and sens for codes*
```{r}
source("load_model_data.R")
rm( ag_data, data_3, index, readm, rrr_all, rrr_data, ae_data, master, rrr_30, rrr_90, train_data, index_ae, no_na_data_sno)
source("creating_result_lists.R")
```
Model function for x-validation
```{r}
calcSens <- function(x) {
        y <- x['Yes', 'Yes']/sum(x[ ,'Yes'])
}
calcSpec <- function(x) {
        y <- x['No', 'No']/sum(x[ ,'No'])
}

getSensSpec <- function(my_data, getModelResults, no_splits = 10) {
  shuffled <- sample(nrow(my_data), replace = FALSE)
  batch_size <- floor(length(shuffled)/no_splits)
  results <- list()
  for (i in 0:(no_splits-1)) {
    if (i == no_splits - 1) {
      test_rows <- shuffled[(i*batch_size + 1):length(shuffled)]
    } else {
      test_rows <- shuffled[1:batch_size + i*batch_size]
    }
    train_rows <- shuffled[!(shuffled %in% test_rows)]
    train <- my_data[train_rows, ]
    test <- my_data[test_rows, ]
    results <- append(results, getModelResults(train = train, test = test))
  }
  result_df <- data.frame(matrix(unlist(results), nrow=10, byrow=T))
  colnames(result_df) <-c("TN", "FP", "FN", "TP", "AUC")
  result_df <- mutate(result_df, pos = TP + FN, neg = TN + FP, sens = TP/pos, spec = TN/neg, accuracy = (TN+TP)/(pos+neg))
  
  c(sensitivity = mean(result_df$sens) ,
    specificity = mean(result_df$spec),
   AUC = mean(result_df$AUC),
   Accuracy = mean(result_df$accuracy))
}

```
Baseline
```{r}
x <- table(AE_frame$cat_30)
sens = x['TP']/(x['TP']+x['FN'])
spec = x['TN']/(x['TN']+x['FP']) 
auc = sens * spec + sens * (1-spec)/2 + spec*(1-sens)/2
Accuracy = (x['TP'] + x['TN'])/(x['TP']+x['FN'] + x['TN'] + x['FP'])
res_30 <- c(sens[[1]], spec[[1]], auc[[1]], Accuracy[[1]])
x <- table(AE_frame$cat_90)
sens = x['TP']/(x['TP']+x['FN'])
spec = x['TN']/(x['TN']+x['FP']) 
auc = sens * spec + sens * (1-spec)/2 + spec*(1-sens)/2
Accuracy = (x['TP'] + x['TN'])/(x['TP']+x['FN'] + x['TN'] + x['FP'])
res_90 <- c(sens[[1]], spec[[1]], auc[[1]], Accuracy[[1]])
all_results_30[['Open comparison']] <- res_30
all_results_90[['Open comparison']] <- res_90
code_results_30[['Open comparison']] <- res_30
code_results_90[['Open comparison']] <- res_90
```
**Random forest**
```{r}
all_results_30[['Random forest crude ']] <- getSensSpec(data_30_n, function(train, test) {
  cross_model <- ranger(has_AE~., data = train)
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
all_results_90[['Random forest crude ']] <- getSensSpec(data_90_n, function(train, test) {
  cross_model <- ranger(has_AE~., data = train)
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})

```

*Adjusting weights for higher spec*
```{r}
all_results_30[['Random forest weighted']] <- getSensSpec(data_30_n, function(train, test) {
  cross_model <- ranger(has_AE~., data = train, case.weights = (1 +(train$has_AE == 0)*4.5))
  p <- predict(cross_model, data = test)
  rangerRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rangerRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
all_results_90[['Random forest weighted']] <- getSensSpec(data_90_n, function(train, test) {
  cross_model <- ranger(has_AE~., data = train, case.weights = (1 +(train$has_AE == 0)*3.5))
  p <- predict(cross_model, data = test)
  rangerRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rangerRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
```

**Logistisk regression** 
```{r}
all_results_30[['Logistic regresssion crude']] <- 
  getSensSpec(data_30_n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
all_results_90[['Logistic regresssion crude']] <- 
  getSensSpec(data_90_n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

all_results_30[['Logistic regresssion weighted']] <- 
  getSensSpec(data_30_n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train, 
                           weights = (1 +(train$has_AE == 0)*2))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(logRoc))
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
all_results_90[['Logistic regresssion weighted']] <- 
  getSensSpec(data_90_n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train, 
                           weights = (1 +(train$has_AE == 0)*1))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
```
With splines
```{r}
all_results_30[['Logistic regresssion splines crude']] <- 
  getSensSpec(data_30_n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

all_results_90[['Logistic regresssion splines crude']] <- 
  getSensSpec(data_90_n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)#, 
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

all_results_30[['Logistic regresssion splines weighted']] <- 
  getSensSpec(data_30_n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train,
                           weights = (1 +(train$has_AE == 0)*2))
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

all_results_90[['Logistic regresssion splines weighted']] <- 
  getSensSpec(data_90_n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train,
                           weights = (1 +(train$has_AE == 0)*2.7))
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
```
**SVM**
```{r}
 all_results_30[['SVM crude']] <- getSensSpec(data_30, function(train, test) {
  cross_model <- svm(has_AE~., data = train)
  p <- predict(cross_model, newdata = test)
  p <- ifelse(p == "Yes", 1, 0)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
}) 
 all_results_90[['SVM crude']] <- getSensSpec(data_90, function(train, test) {
   cross_model <- svm(has_AE~., data = train)
  p <- predict(cross_model, newdata = test)
  p <- ifelse(p == "Yes", 1, 0)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
})  
all_results_30[['SVM weighted']] <- getSensSpec(data_30, function(train, test) {
  cross_model <- svm(has_AE~., data = train, class.weights = c(Yes =  1, No = 2.5))
  p <- predict(cross_model, newdata = test)
  p <- ifelse(p == "Yes", 1, 0)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
}) 
 all_results_90[['SVM weighted']] <- getSensSpec(data_90, function(train, test) {
   cross_model <- svm(has_AE~., data = train, class.weights = c(Yes =  1, No = 2))
  p <- predict(cross_model, newdata = test)
  p <- ifelse(p == "Yes", 1, 0)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
}) 
```

```{r}
all_results_30
```
```{r}
all_results_90
```


Fractures and electives
Baseline
```{r}
x <- table(fx_frame$cat_30)
sens = x['TP']/(x['TP']+x['FN'])
spec = x['TN']/(x['TN']+x['FP']) 
auc = sens * spec + sens * (1-spec)/2 + spec*(1-sens)/2
Accuracy = (x['TP'] + x['TN'])/(x['TP']+x['FN'] + x['TN'] + x['FP'])
res_30 <- c(sens[[1]], spec[[1]], auc[[1]], Accuracy[[1]])
x <- table(fx_frame$cat_90)
sens = x['TP']/(x['TP']+x['FN'])
spec = x['TN']/(x['TN']+x['FP']) 
auc = sens * spec + sens * (1-spec)/2 + spec*(1-sens)/2
Accuracy = (x['TP'] + x['TN'])/(x['TP']+x['FN'] + x['TN'] + x['FP'])
res_30 <- c(sens[[1]], spec[[1]], auc[[1]], Accuracy[[1]])
all_results_fx_30[['Open comparison']] <- res_30
all_results_fx_90[['Open comparison']] <- res_90
```
```{r}
all_results_fx_30[['Random forest fractures crude']] <- getSensSpec(fx30n, function(train, test) {
  cross_model <- ranger(has_AE~., data = train)
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
all_results_fx_90[['Random forest fractures crude']] <- getSensSpec(fx90n, function(train, test) {
  cross_model <- ranger(has_AE~., data = train)
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
all_results_fx_30[['Random forest fractures weighted']] <- getSensSpec(fx30n, function(train, test) {
  cross_model <- ranger(has_AE~., data = train, case.weights = (1 +(train$has_AE == 0)*20))
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
all_results_fx_90[['Random forest fractures weighted']] <- getSensSpec(fx90n, function(train, test) {
  cross_model <- ranger(has_AE~., data = train, case.weights = (1 +(train$has_AE == 0)*11))
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
```
Logistic regression
```{r}
all_results_fx_30[['Logistic regresssion fractures weighted']] <- 
  getSensSpec(fx30n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train,
                           weights = (1 +(train$has_AE == 0)*3.3))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
all_results_fx_90[['Logistic regresssion fractures weighted']] <- 
  getSensSpec(fx90n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train,
                           weights = (1 +(train$has_AE == 0)*3))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
```
```{r}
all_results_fx_30[['Logistic regresssion fractures splines weighted']] <- 
  getSensSpec(fx30n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train, 
                           weights = (1 +(train$has_AE == 0)*4.5))
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

all_results_fx_90[['Logistic regresssion fractures splines weighted']] <- 
  getSensSpec(fx90n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train, 
                           weights = (1 +(train$has_AE == 0)*3))
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
```
```{r}
  all_results_fx_30[['SVM fractures weighted']] <- getSensSpec(fx30, function(train, test) {
  cross_model <- svm(has_AE~., data = train, class.weights = c(Yes =  1, No = 7))
  p <- predict(cross_model, newdata = test)
  p <- ifelse(p == "Yes", 1, 0)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
}) 
 all_results_fx_90[['SVM fractures weighted']] <- getSensSpec(fx90, function(train, test) {
   cross_model <- svm(has_AE~., data = train, class.weights = c(Yes =  1, No = 4))
  p <- predict(cross_model, newdata = test)
  p <- ifelse(p == "Yes", 1, 0)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
}) 
```
```{r}
all_results_fx_30
```
```{r}
all_results_fx_90
```
```{r}
x <- table(el_frame$cat_30)
sens = x['TP']/(x['TP']+x['FN'])
spec = x['TN']/(x['TN']+x['FP']) 
auc = sens * spec + sens * (1-spec)/2 + spec*(1-sens)/2
Accuracy = (x['TP'] + x['TN'])/(x['TP']+x['FN'] + x['TN'] + x['FP'])
res_30 <- c(sens[[1]], spec[[1]], auc[[1]], Accuracy[[1]])
x <- table(el_frame$cat_90)
sens = x['TP']/(x['TP']+x['FN'])
spec = x['TN']/(x['TN']+x['FP']) 
auc = sens * spec + sens * (1-spec)/2 + spec*(1-sens)/2
Accuracy = (x['TP'] + x['TN'])/(x['TP']+x['FN'] + x['TN'] + x['FP'])
res_30 <- c(sens[[1]], spec[[1]], auc[[1]], Accuracy[[1]])
all_results_el_30[['Open comparison']] <- res_30
all_results_el_90[['Open comparison']] <- res_90
```
```{r}
all_results_el_30[['Random forest elective crude']] <- getSensSpec(el30n, function(train, test) {
  cross_model <- ranger(has_AE~., data = train)
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
all_results_el_90[['Random forest elective crude']] <- getSensSpec(el90n, function(train, test) {
  cross_model <- ranger(has_AE~., data = train)
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})

all_results_el_30[['Random forest elective weighted']] <- getSensSpec(el30n, function(train, test) {
  cross_model <- ranger(has_AE~., data = train, case.weights = (1 +(train$has_AE == 0)*3.5))
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
all_results_el_90[['Random forest elective weighted']] <- getSensSpec(el90n, function(train, test) {
  cross_model <- ranger(has_AE~., data = train, case.weights = (1 +(train$has_AE == 0)*2.7))
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})

  all_results_el_30[['Logistic regresssion elective crude']] <- 
  getSensSpec(el30n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
all_results_el_90[['Logistic regresssion elective crude']] <- 
  getSensSpec(el90n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
all_results_el_30[['Logistic regresssion elective weighted']] <- 
  getSensSpec(el30n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train,
                           weights = (1 +(train$has_AE == 0)*1.3))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
all_results_el_90[['Logistic regresssion elective weighted']] <- 
  getSensSpec(el90n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train,
                           weights = (1 +(train$has_AE == 0)*.8))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

all_results_el_30[['Logistic regresssion elective splines crude']] <- 
  getSensSpec(el30n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

all_results_el_90[['Logistic regresssion elective splines crude']] <- 
  getSensSpec(el90n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

all_results_el_30[['Logistic regresssion elective splines weighted']] <- 
  getSensSpec(el30n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train, 
                           weights = (1 +(train$has_AE == 0)*1.3))
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

all_results_el_90[['Logistic regresssion elective splines weighted']] <- 
  getSensSpec(el90n, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train, 
                           weights = (1 +(train$has_AE == 0)*.8))
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

all_results_el_30[['SVM elective crude']] <- getSensSpec(el30, function(train, test) {
  cross_model <- svm(has_AE~., data = train)
  p <- predict(cross_model, newdata = test)
  p <- ifelse(p == "Yes", 1, 0)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
}) 
 all_results_el_90[['SVM elective crude']] <- getSensSpec(el90, function(train, test) {
   cross_model <- svm(has_AE~., data = train)
  p <- predict(cross_model, newdata = test)
  p <- ifelse(p == "Yes", 1, 0)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
})
 all_results_el_30[['SVM elective weighted']] <- getSensSpec(el30, function(train, test) {
  cross_model <- svm(has_AE~., data = train, class.weights = c(Yes =  1, No = 2))
  p <- predict(cross_model, newdata = test)
  p <- ifelse(p == "Yes", 1, 0)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
}) 
 all_results_el_90[['SVM elective weighted']] <- getSensSpec(el90, function(train, test) {
   cross_model <- svm(has_AE~., data = train, class.weights = c(Yes =  1, No = 1.8))
  p <- predict(cross_model, newdata = test)
  p <- ifelse(p == "Yes", 1, 0)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
})
```

```{r}
all_results_el_30
```
```{r}
all_results_el_90
```

**Random forest with codes**
```{r}
code_results_30[['Random forest 30 codes crude']] <- getSensSpec(data_wc_30, function(train, test) {
  cross_model <- ranger(has_AE~., data = train)
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
code_results_30[['Random forest 30 index-codes crude']] <- getSensSpec(data_wc_30_i, function(train, test) {
  cross_model <- ranger(has_AE~., data = train)
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})

code_results_30[['Random forest 30 codes weighted']] <- getSensSpec(data_wc_30, function(train, test) {
  cross_model <- ranger(has_AE~., data = train, case.weights = (1 +(train$has_AE == 0)*10))
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
code_results_30[['Random forest 30 index-codes weighted']] <- getSensSpec(data_wc_30_i, function(train, test) {
  cross_model <- ranger(has_AE~., data = train, case.weights = (1 +(train$has_AE == 0)*10))
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
code_results_90[['Random forest 90 codes crude']] <- getSensSpec(data_wc_90, function(train, test) {
  cross_model <- ranger(has_AE~., data = train)
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})

code_results_90[['Random forest 90 index-codes crude']] <- getSensSpec(data_wc_90_i, function(train, test) {
  cross_model <- ranger(has_AE~., data = train)
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
code_results_90[['Random forest 90 codes weighted']] <- getSensSpec(data_wc_90, function(train, test) {
  cross_model <- ranger(has_AE~., data = train, case.weights = (1 +(train$has_AE == 0)*3.5))
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})

code_results_90[['Random forest 90 index-codes weighted']] <- getSensSpec(data_wc_90_i, function(train, test) {
  cross_model <- ranger(has_AE~., data = train, case.weights = (1 +(train$has_AE == 0)*3.5))
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
```

**Logistisk regression with codes**
```{r}
code_results_30[['Logistic regresssion 30 codes crude']] <- 
  getSensSpec(data_wc_30, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
code_results_30[['Logistic regresssion 30 index-codes crude']] <- 
  getSensSpec(data_wc_30_i, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
code_results_30[['Logistic regresssion 30 codes weighted']] <- 
  getSensSpec(data_wc_30, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train,
                           weights = (1 +(train$has_AE == 0)*2))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
code_results_30[['Logistic regresssion 30 index-codes weighted']] <- 
  getSensSpec(data_wc_30_i, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train,
                           weights = (1 +(train$has_AE == 0)*2))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

code_results_30[['Logistic regresssion 30 splines codes crude']] <- 
  getSensSpec(data_wc_30, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)#, 
                          # weights = (1 +(train$has_AE == "No")*.5))
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
code_results_30[['Logistic regresssion 30 splines index-codes crude']] <- 
  getSensSpec(data_wc_30_i, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

code_results_30[['Logistic regresssion 30 codes splines weighted']] <- 
  getSensSpec(data_wc_30, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train, 
                           weights = (1 +(train$has_AE == 0)*2))
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
code_results_30[['Logistic regresssion 30 splines index-codes weighted']] <- 
  getSensSpec(data_wc_30_i, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train, 
                           weights = (1 +(train$has_AE == 0)*2.5))
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
code_results_90[['Logistic regresssion 90 codes crude']] <- 
  getSensSpec(data_wc_90, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

code_results_90[['Logistic regresssion 90 index-codes crude']] <- 
  getSensSpec(data_wc_90_i, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
code_results_90[['Logistic regresssion 90 codes weighted']] <- 
  getSensSpec(data_wc_90, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train,
                           weights = (1 +(train$has_AE == 0)*1))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

code_results_90[['Logistic regresssion 90 index-codes weighted']] <- 
  getSensSpec(data_wc_90_i, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train,
                           weights = (1 +(train$has_AE == 0)*1.2))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
    p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
code_results_90[['Logistic regresssion 90 splines codes crude']] <- 
  getSensSpec(data_wc_90, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

code_results_90[['Logistic regresssion 90 splines codes weighted ']] <- 
  getSensSpec(data_wc_90, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train, 
                           weights = (1 +(train$has_AE == 0)*2))
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })

code_results_90[['Logistic regresssion 90 splines index-codes crude']] <- 
  getSensSpec(data_wc_90_i, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train)
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
code_results_90[['Logistic regresssion 90 splines index-codes weighted']] <- 
  getSensSpec(data_wc_90_i, function(train, test) {
    cross_model_log <- glm(has_AE ~., 
                           family = binomial(link = logit), 
                           data = train, 
                           weights = (1 +(train$has_AE == 0)*1.2))
    cross_model_log %<>% update(.~.- los + ns(los, 4))
    p <- predict(cross_model_log, newdata = test, type = "response")
    logRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(logRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p > 0.5, "Yes", "No")
    list(table(predicted = p, true=test$has_AE), auc_res)
  })
```
```{r}
 code_results_30[['SVM 30 codes crude']] <- getSensSpec(data_wc_30, function(train, test) {
  cross_model <- svm(has_AE~., data = train)
  p <- predict(cross_model, newdata = test)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
})
 code_results_30[['SVM 30 index-codes crude']] <- getSensSpec(data_wc_30_i, function(train, test) {
  cross_model <- svm(has_AE~., data = train)
  p <- predict(cross_model, newdata = test)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
})
 code_results_30[['SVM 30 codes weighted']] <- getSensSpec(data_wc_30_l, function(train, test) {
 cross_model <- svm(has_AE~., data = train, class.weights = c(Yes =  1, No = 14))
  p <- predict(cross_model, newdata = test)
  p <- ifelse(p == "Yes", 1, 0)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
})
  
 code_results_30[['SVM 30 index-codes weighted']] <- getSensSpec(data_wc_30_i_l, function(train, test) {
  cross_model <- svm(has_AE~., data = train, class.weights = c(Yes =  1, No = 14))
  p <- predict(cross_model, newdata = test)
  p <- ifelse(p == "Yes", 1, 0)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
})
 code_results_90[['SVM 90 codes crude']] <- getSensSpec(data_wc_90, function(train, test) {
  cross_model <- svm(has_AE~., data = train)
  p <- predict(cross_model, newdata = test)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
})
 
 code_results_90[['SVM 90 index-codes crude']] <- getSensSpec(data_wc_90_i, function(train, test) {
  cross_model <- svm(has_AE~., data = train)
  p <- predict(cross_model, newdata = test)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
})
  code_results_90[['SVM 90 codes weighted']] <- getSensSpec(data_wc_90_l, function(train, test) {
   cross_model <- svm(has_AE~., data = train, class.weights = c(Yes =  1, No = 5))
  p <- predict(cross_model, newdata = test)
  p <- ifelse(p == "Yes", 1, 0)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
})
 
 code_results_90[['SVM 90 index-codes weighted']] <- getSensSpec(data_wc_90_i_l, function(train, test) {
   cross_model <- svm(has_AE~., data = train, class.weights = c(Yes =  1, No = 5))
  p <- predict(cross_model, newdata = test)
  p <- ifelse(p == "Yes", 1, 0)
  svmRoc <- data.frame(response = test$has_AE, predictor = p) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- (auc(svmRoc))
  p <- ifelse(p< 0.5, "No", "Yes")
  list(table(predicted = p, true=test$has_AE), auc_res)
})
```
```{r}
code_results_30
```
```{r}
code_results_90
```
preparing data for nn
```{r}

nn_data <- data_wc

for (i in unique(nn_data$sex)){
  nn_data[, paste0(i)]=ifelse(nn_data$sex==i,1,0)
}
for (i in unique(nn_data$fx)){
  nn_data[, paste0(i)]=ifelse(nn_data$fx==i,1,0)
}
for (i in unique(nn_data$type)){
  nn_data[, paste0(i)]=ifelse(nn_data$type==i,1,0)
}

nn_data$sex <- NULL
nn_data$type <- NULL
nn_data$fx <- NULL
nn_data$cause <- NULL
nn_data$county <- NULL
nn_data$op_date<- NULL

scl <- function(x) {(x - min(x))/(max(x) - min(x))}
nn_data[, 3:11] <- data.frame(lapply(nn_data[,3:11], scl))
nn_data_30_wc <- select(nn_data, -rrr_90, -index_ae, -pos_90, has_AE = rrr_30)
nn_data_90_wc <- select(nn_data, -rrr_30, -index_ae, -pos_30, has_AE = rrr_90)
nn_data_30 <- select(nn_data_30_wc, -pos_30)
nn_data_90 <- select(nn_data_90_wc, -pos_90)
```

NN with tensor flow
```{r}
library(tfruns)
training_run("nn_model.R")
compare_runs()
test_runs <- ls_runs()
```
```{r}
nn_results = list()
class(nn_results) <- c("results_class", class(nn_results))
print.results_class <- function(l) {
 if (length(l) == 0) {
  cat('\n None')
  return()
 }

 sapply(l, USE.NAMES = TRUE, simplify = FALSE, function(vals) {
  sapply(vals, function(v) {
   sprintf("%.3f", v)
  })
 }) %>% 
  do.call(rbind, .) %>% 
  knitr::kable() %>% 
  print
}
```



```{r, echo=FALSE}
outcome <- nn_data_90$has_AE
  outcome <- to_categorical(outcome, 2)
  
for_nn <- list(
    outcome = outcome,
    data = nn_data_90 %>% select(-has_AE) %>% as.matrix()
  )

calcSensNn <- function(x) {
  y <- x['1', '1']/sum(x[ ,'1'])
}
calcSpecNn <- function(x) {
  y <- x['0', '0']/sum(x[ ,'0'])
}


getSensSpecNn <- function(my_data, getModelResults, no_splits = 10) {
  shuffled <- sample(nrow(my_data$outcome), replace = FALSE)
  batch_size <- floor(length(shuffled)/no_splits)
  results <- list()
  for (i in 0:(no_splits-1)) {
    if (i == no_splits - 1) {
      test_rows <- shuffled[(i*batch_size + 1):length(shuffled)]
    } else {
      test_rows <- shuffled[1:batch_size + i*batch_size]
    }
    train_rows <- shuffled[!(shuffled %in% test_rows)]
    a <- my_data$outcome[train_rows,]
    b <- my_data$data[train_rows,]
    train <- list(outcome = a, data = b)
    c <- my_data$outcome[-train_rows,]
    d <- my_data$data[-train_rows,]
    test <- list(outcome = c, data = d)
    results <- append(results, getModelResults(train = train, test = test))
  }
  result_df <- data.frame(matrix(unlist(results), nrow=10, byrow=T))
  colnames(result_df) <-c("TN", "FP", "FN", "TP", "AUC")
  result_df <- mutate(result_df, pos = TP + FN, neg = TN + FP, sens = TP/pos, spec = TN/neg, accuracy = (TN+TP)/(pos+neg))
  xres <<- result_df
  c(sensitivity = mean(result_df$sens) ,
    specificity = mean(result_df$spec),
   AUC = mean(result_df$AUC),
   Accuracy = mean(result_df$accuracy))
}

nn_results[['NN 90']] <- getSensSpecNn(for_nn, function(train, test) {
 model <- keras_model_sequential() %>% 
  layer_dense(units = 49, activation = 'relu', input_shape = ncol(test$data)) %>% 
  layer_dropout(rate = 0.4) %>% 
  layer_dense(units = 100, activation = 'relu') %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 50, activation = 'relu') %>%
  layer_dropout(rate = 0.3) %>%
 
layer_dense(units = 2, activation = 'softmax')

model %>% compile(
  loss = 'binary_crossentropy',
  optimizer = optimizer_rmsprop(lr = 0.003),
  metrics = c('accuracy'))

history <- model %>% fit(
  train$data, train$outcome, 
  epochs = 60, batch_size = 128, 
  validation_split = 0.2)

model %>% evaluate(test$data, test$outcome, batch_size = 32)
pred <- model %>% predict(test$data, batch_size = 32)
y <- apply(pred, 1, function(v) which.max(v))
y <- ifelse(y==2, 1, 0)
nnRoc <- data.frame(response = test$outcome[,2], predictor = y) %>%
  arrange(predictor) %>%
  with(., roc(response, predictor))
auc_nn <- (auc(nnRoc))

list(table(predicted = y, true=test$outcome[,2]), auc_nn)
})
nn_results
```
```{r}
nn_results
```

**Neurala networks with and without codes**
```{r}
nn_data <- no_na_data_wc %>%
        select(has_AE, sex, fx, type, pos_90, age, los, readmissions, op_date, VTID_Mean, VTID_P50, VTID_P75, VTID_P90, VTID_P95, VTID_StdDev)
nn_data$has_AE <- ifelse(nn_data$has_AE == "Yes", 1, 0)
nn_data$fx <- ifelse(nn_data$fx == "Yes", 1, 0)
nn_data$sex <- ifelse(nn_data$sex == "Female", 0, 1)
nn_data$type <- ifelse(nn_data$type == "university", 1, ifelse(nn_data$type == "county", 2, ifelse(nn_data$type == "countypart", 3, 0)))
scl <- function(x) {(x - min(x))/(max(x) - min(x))}
nn_data[, 6:ncol(nn_data)] <- data.frame(lapply(nn_data[,6:ncol(nn_data)], scl))
no_splits <- 10

all_results[['Neural network without codes crude']] <- 
  getSensSpec(nn_data, function(train, test) {
        n <- names(train)
        f <- as.formula(paste("has_AE ~", paste(n[!n %in% "has_AE"], collapse = " + ")))
        cross_model <- neuralnet(f, 
                                 data = train, 
                                 hidden = c(5, 3), 
                                 act.fct = "logistic", 
                                 linear.output = FALSE, 
                                 lifesign = "minimal",
                                 stepmax = (8 * 1e6))
        p <- compute(cross_model, test[, -1])
        p1 <- p$net.result
        fpred <- ifelse(p1>0.5, 'Yes', 'No')
        fkey <- factor(test$has_AE, levels = c(0, 1), labels=c('No', 'Yes'))
        ret <- table(predicted = fpred, true=fkey)
        list(ret)
  })
```
Test without cross-validation
```{r}
rf <- randomForest(has_AE~., data = no_na_data)
rf_tbl <- table(predicted = predict(rf), true=no_na_data$has_AE)

log <- glm(has_AE ~., data = no_na_data, family = binomial(link = logit))
log_p <- predict(log, newdata = no_na_data, type = "response")
log_p <- ifelse(log_p > 0.5, "Yes", "No")
log_tbl <- table(predicted = log_p, true=no_na_data$has_AE)

all_results[['RF-without x-validation']] <- c(calcSens(rf_tbl), calcSpec(rf_tbl))
all_results[['Log-without x-validation']] <- c(calcSens(log_tbl), calcSpec(log_tbl))
```

|                                        |sens  |spec  |
|:---------------------------------------|:-----|:-----|
|Logistic regresssion weighted           |0.431 |0.817 |
|Logistic regresssion weighted - los     |0.423 |0.819 |
|Neural networ without codes crude       |0.759 |0.537 |
|Random forest crude                     |0.753 |0.456 |
|Random forest weighted                  |0.397 |0.800 |
|SVM weighted                            |0.420 |0.808 |
|Random forest with codes weighted       |0.452 |0.836 |
|Logistic regression with codes weighted |0.510 |0.808 |

```{r}

all_results_90[['Random forest crude1']] <- getSensSpec(data_90_n, function(train, test) {
  cross_model <- ranger(has_AE~., data = train, seed = 11)
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})

all_results_90[['Random forest crude tweak']] <- getSensSpec(data_90_n, function(train, test) {
  cross_model <- ranger(has_AE~., data = train, seed = 11, mtry = 2)#, num.trees = 800)
  p <- predict(cross_model, data = test )
  rfRoc <- data.frame(response = test$has_AE, predictor = p$predictions) %>%
    arrange(predictor) %>%
    with(., roc(response, predictor))
  auc_res <- auc(rfRoc)
  test$has_AE <- factor(test$has_AE > 0, levels = c(FALSE, TRUE), labels = c("No", "Yes"))
  p$predictions <- ifelse(p$predictions< 0.5, "No", "Yes")
  list(table(predicted = p$predictions, true=test$has_AE), auc_res)
})
all_results_90
  

# TODO - test without crossvalidation, i.e. just directly calculate the sens/spec
# probably not a good idea as test/train must differ
getSensSpecBoot <- function(my_data, ...) {
  bootResults <- boot(data = my_data, 
                      R = 100, 
                      parallel = 'multicore',
                      statistic = function(data, indices) {
                        getSensSpec(my_data = data[indices, ], ...)
                      })
  
  sapply(1:length(bootResults$t0), function(i) {
    name <- names(bootResults$t0)[i]
    res <- c(
      bootResults$t0[i],
      boot.ci(bootResults, type="perc", index=i)$percent[4:5])
    names(res) <- c(name, paste(name, c("2.5", "97.5")))
    return(list(res))
  }) %>% do.call(c, .)
}
```
42